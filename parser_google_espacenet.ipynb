{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPns/FkzF9+1Dpi4+FrEcEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galrat/parsing/blob/main/parser_google_espacenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZIq2SFhdUqX",
        "outputId": "f89d88dd-9286-429c-d15e-54e3442a1b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.16.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.16.0 trio-0.24.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as ec\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n"
      ],
      "metadata": {
        "id": "5wTHdaYLelVg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# defs"
      ],
      "metadata": {
        "id": "abomb5QSgsiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_claim_google(soup):\n",
        "  all = soup.find_all('div', class_='flex flex-width style-scope patent-result')[-1].find_all('div', class_='claim-text style-scope patent-text')[1]\n",
        "  return all.text\n",
        "\n",
        "def get_claim_google_2(soup):\n",
        "  try:\n",
        "      # all\n",
        "      try:\n",
        "          try:\n",
        "              all = soup.find('div', class_='claim-text style-scope patent-text').find('span', class_='notranslate style-scope patent-text').text\n",
        "          except:\n",
        "              all = soup.find('div', class_='claim-text style-scope patent-text').text\n",
        "          #print('all', all)\n",
        "      except:\n",
        "          all = soup.find('section', id='claims').find('span', class_='notranslate style-scope patent-text').text\n",
        "          #print('all', all)\n",
        "\n",
        "      # original\n",
        "      try:\n",
        "          original = soup.find('div', class_='claim-text style-scope patent-text').find('span',\n",
        "                                                                                        class_='notranslate style-scope patent-text').find(\n",
        "              'span').text\n",
        "      except:\n",
        "          try:\n",
        "              original = soup.find('section', id='claims').find('span',\n",
        "                                                                class_='notranslate style-scope patent-text').find(\n",
        "                  'span').text\n",
        "          except:\n",
        "              original = ''\n",
        "      #print('original', original)\n",
        "\n",
        "      # translation\n",
        "      claim_1 = all.replace(original, '')\n",
        "      #print('claim 1:', claim_1)\n",
        "  except:\n",
        "      claim_1 = 'no_data'\n",
        "  if claim_1 == '' or claim_1 == 'no_data':\n",
        "    try:\n",
        "      claim_1 = soup.find_all('div', class_='flex flex-width style-scope patent-result')[-1].find_all('div', class_='claim-text style-scope patent-text')[1].text\n",
        "    except:\n",
        "      claim_1 = 'no_data'\n",
        "  return claim_1"
      ],
      "metadata": {
        "id": "xBzTYo8AMeB6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_google_patent(soup):\n",
        "\n",
        "  # title\n",
        "  title = soup.find('div', id='wrapper').find('h1', id='title').text.replace('\\n', '').strip()\n",
        "  #print('title:', title)\n",
        "\n",
        "  # patent_number\n",
        "  patent_number = soup.find('h2', id='pubnum').text.strip().replace('\\n', '').replace('\\t', '')\n",
        "  #print('patent_number:', patent_number)\n",
        "\n",
        "  # applicant\n",
        "  author_counter = 0\n",
        "  applicant_counter = 0\n",
        "  counter = 0\n",
        "  author_check = 0\n",
        "  applicant_check = 0\n",
        "  important_people_data = soup.find('dl', class_='important-people style-scope patent-result')\n",
        "  for i in important_people_data.find_all('dt', class_='style-scope patent-result'):\n",
        "      if 'Inventor' in i.text:\n",
        "          author_counter = counter\n",
        "          author_check = 1\n",
        "      if 'Assignee' in i.text:\n",
        "          applicant_counter = counter\n",
        "          applicant_check = 1\n",
        "      counter += 1\n",
        "  #print('author_counter', author_counter, 'applicant_counter', applicant_counter)\n",
        "\n",
        "  authors = ''\n",
        "  if author_check == 1:\n",
        "      try:\n",
        "          authors_data = soup.find('dl', class_='important-people style-scope patent-result')\n",
        "          authors_data = authors_data.find_all('dt', class_='style-scope patent-result')[\n",
        "              author_counter].find_next_siblings('dd')\n",
        "          for author in authors_data:\n",
        "              if '\\n' in author.text:\n",
        "                  break\n",
        "              authors = authors + author.text + ';'\n",
        "          authors = authors.replace('\\n', '')\n",
        "      except:\n",
        "          #print('no authors data')\n",
        "          authors = ('no authors data')\n",
        "  else:\n",
        "      authors = 'no_data'\n",
        "\n",
        "  applicants = ''\n",
        "  if applicant_check == 1:\n",
        "      try:\n",
        "          applicants_data = soup.find('dl', class_='important-people style-scope patent-result')\n",
        "          applicants_data = applicants_data.find_all('dt', class_='style-scope patent-result')[\n",
        "              applicant_counter].find_next_siblings('dd')\n",
        "          for applicant in applicants_data:\n",
        "              applicants = applicants + applicant.text.strip() + ';'\n",
        "          applicants = applicants.replace('\\n', '').strip()\n",
        "      except:\n",
        "          #print('no applicants data')\n",
        "          applicants = ('no applicants data')\n",
        "  else:\n",
        "      applicants = 'no_data'\n",
        "\n",
        "  # filing_date\n",
        "  filind_date = 'no_data'\n",
        "  publication_date = 'no_data'\n",
        "  status = 'no_data'\n",
        "  dates_data = soup.find_all('div', class_='event layout horizontal style-scope application-timeline')\n",
        "  for data in dates_data:\n",
        "      if 'filed by' in data.text:\n",
        "          filind_date = data.text.split('Application')[0]\n",
        "          #print('filing date:', filind_date)\n",
        "      if 'Publication' in data.text:\n",
        "          publication_date = data.text.split('Publication')[0]\n",
        "          #print('Publication date:', publication_date)\n",
        "      if 'Status' in  data.text:\n",
        "          status = data.text.split('Status')[1].replace('\\n', '').replace('\\t', '')\n",
        "          #print('Status:', status)\n",
        "\n",
        "  # application number\n",
        "  try:\n",
        "      application_number = soup.find_all('div', class_='header style-scope application-timeline')[1].text\n",
        "      application_number = application_number.split('Application')[1].split('events')[0].replace(' ','')\n",
        "  except:\n",
        "      print('no application number data')\n",
        "      application_number = 'no data'\n",
        "  #print('application_number', application_number)\n",
        "\n",
        "\n",
        "  patent_type = 'no_data'\n",
        "  #print('ipc text', soup.find('div', class_='style-scope classification-viewer').find('div', 'style-scope classification-tree').text)\n",
        "\n",
        "  ipc_data = 'no_data'\n",
        "  try:\n",
        "      ipcs = soup.find('div', class_='style-scope classification-viewer').find_all('div', class_='style-scope classification-tree')\n",
        "      for ipc in ipcs:\n",
        "          ipc_class = ipc.find(first=True).text.strip().replace('\\n', '').replace('\\t', '')\n",
        "          #print('ipc', ipc_class)\n",
        "      #print(ipc_class)\n",
        "  except:\n",
        "      ipc_data = 'no_data'\n",
        "\n",
        "  ipc_datas = soup.find_all('div', class_='style-scope classification-tree')\n",
        "  for i in ipc_datas[:1]:\n",
        "      target = i.find_all(class_='code style-scope classification-tree')\n",
        "      #print('target ipc', target[-1].text)\n",
        "      # print(i.text.strip())\n",
        "      ipc_data = target[-1].text\n",
        "\n",
        "  # claim 1\n",
        "  claim_1 = ''\n",
        "  try:\n",
        "    claim_1 = get_claim_google_2(soup)\n",
        "    #print('claim_1 google', claim_1)\n",
        "  except:\n",
        "    print('no claims')\n",
        "\n",
        "  # abstract\n",
        "  abstract = ''\n",
        "  try:\n",
        "    abstract_orig = soup.find('section', id='abstract').find('span', class_='google-src-text style-scope patent-text').text#.text.replace('\\n', '').replace('\\t', '').replace('Abstracttranslated from ', '')\n",
        "    #print('abstract_orig', abstract_orig)\n",
        "    abstract_all = soup.find('section', id='abstract').text\n",
        "    #print('abstract_all', abstract_all)\n",
        "    abstract_eng = abstract_all.replace(abstract_orig, '').strip()\n",
        "    abstract_eng = abstract_eng.replace('\\n', '')\n",
        "    #print('abstract_eng', abstract_eng)\n",
        "    abstract = abstract_eng\n",
        "  except:\n",
        "    abstract = soup.find('section', id='abstract').text.replace('\\n', '')\n",
        "\n",
        "\n",
        "  # other applications county code\n",
        "  others = ''\n",
        "  other_app = soup.find('div', class_='wrap style-scope application-timeline').find('div',\n",
        "                                                                                    class_='event style-scope application-timeline').find_all(\n",
        "      'a')\n",
        "  for other in other_app:\n",
        "      country_code = other.text.strip()\n",
        "      others += country_code + ','\n",
        "  #print(others)\n",
        "\n",
        "  printing = 0\n",
        "  while printing:\n",
        "      print('patent_number:', patent_number)\n",
        "      print('application_number:', application_number)\n",
        "      print('title:', title)\n",
        "      print('type:', patent_type)\n",
        "      print('filind_date:', filind_date)\n",
        "      print('applicant:', applicants)\n",
        "      print('authors:', authors)\n",
        "      print('ipc_data:', ipc_data)\n",
        "      print('publication_date:', publication_date)\n",
        "      print('abstract:', abstract)\n",
        "      print('claim_1:', claim_1)\n",
        "      print('status:', status)\n",
        "      print('others:', others)\n",
        "      break\n",
        "\n",
        "  header = ['patent number', 'application_number', 'title', 'INV/UM', 'filing_date', 'applicant', 'autors',\n",
        "                          'publiction_date', 'ipc', 'claims', 'status', 'abstract', 'other_applications']\n",
        "  data_line = []\n",
        "  data_line.append(patent_number)\n",
        "  data_line.append(application_number)\n",
        "  data_line.append(title)\n",
        "  data_line.append(patent_type)\n",
        "  data_line.append(filind_date)\n",
        "  data_line.append(applicants)\n",
        "  data_line.append(authors)\n",
        "  data_line.append(publication_date)\n",
        "  data_line.append(ipc_data)\n",
        "  data_line.append(claim_1.replace('\\n', ''))\n",
        "  data_line.append(status)\n",
        "  data_line.append(abstract.replace('\\n', ''))\n",
        "  data_line.append(others[:-1])\n",
        "  return data_line\n"
      ],
      "metadata": {
        "id": "1MEGPidAgu5N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_from_espacenet(espacenet_url):\n",
        "    #print('def', espacenet_url)\n",
        "    data_line2 = []\n",
        "\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    driver.get(espacenet_url)\n",
        "    time.sleep(2)\n",
        "    WebDriverWait(driver, 20).until(ec.visibility_of_element_located((By.ID, 'pagebody')))\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
        "\n",
        "    #print(soup)\n",
        "    #print('---------------------\\n')\n",
        "    # title\n",
        "    title = soup.find('h3').text.strip().replace('\\n', '').replace('\\t', '')\n",
        "    #print('title:', title)\n",
        "    table = soup.find('table', class_='tableType3')\n",
        "    #print(table.text.strip())\n",
        "    app_num = soup.find('h1', class_='noBottomMargin').text.split('―')[0].split('\\n')[-1].strip().replace('\\xa0', '').replace('(', '').replace(')', '')\n",
        "\n",
        "    applicant = ''\n",
        "    authors = ''\n",
        "    ipc = ''\n",
        "    priority = ''\n",
        "    original_application = ''\n",
        "    others= ''\n",
        "\n",
        "    table_lines = table.find_all('tr')\n",
        "    for line in table_lines:\n",
        "      if 'Applicant(s):' in line.text:\n",
        "        applicant = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split())\n",
        "        applicant = applicant.split('+')[0].strip()\n",
        "        #print('applicant:', applicant)\n",
        "\n",
        "      if 'Inventor(s):' in line.text:\n",
        "        authors = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split())\n",
        "        authors = authors.split('+')[0].strip()\n",
        "        #print('authors:', authors)\n",
        "\n",
        "      if 'Classification:' in line.text:\n",
        "        ipc = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split()).split('- cooperative')[0]\n",
        "        ipc = ipc.replace('- international:', '').strip()\n",
        "        ipc = ipc.split('(IPC1-7)')[0].strip()\n",
        "        #print('ipc:', ipc)\n",
        "\n",
        "      if 'Priority number(s):' in line.text:\n",
        "        priority = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split()).split('- cooperative')[0]\n",
        "        #print('Priority:', priority)\n",
        "\n",
        "      if 'Application number:' in line.text:\n",
        "        original_application = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split()).split('- cooperative')[0]\n",
        "        original_application = original_application.replace('Global Dossier', '').strip()\n",
        "        #print('original_application:', original_application)\n",
        "\n",
        "      if 'Also published as:' in line.text:\n",
        "        others = ' '.join(line.find('div', id='lessPublishedAs').text.replace('\\n', '').replace('\\t', '').strip().split()).split('- cooperative')[0]\n",
        "        #others = soup.find('div', id='lessPublishedAs').text.strip()\n",
        "        #print('others:', others)\n",
        "\n",
        "\n",
        "    publication = 'no_data'\n",
        "\n",
        "    abstract = soup.find('div', class_='application article clearfix').find('p').text\n",
        "    #print(abstract)\n",
        "\n",
        "    printing = 0\n",
        "    while printing:\n",
        "        print('title:', title)\n",
        "        print('applicant:', applicant)\n",
        "        print('authors:', authors)\n",
        "        print('ipc:', ipc)\n",
        "        print('priority:', priority)\n",
        "        print('original_application:', original_application)\n",
        "        print('publication:', publication)\n",
        "        print('abstract:', abstract)\n",
        "        print('others:', others)\n",
        "        break\n",
        "\n",
        "    data_line2.append(app_num)\n",
        "    data_line2.append(applicant)\n",
        "    data_line2.append(authors)\n",
        "    data_line2.append(ipc)\n",
        "    data_line2.append(priority)\n",
        "    data_line2.append(original_application)\n",
        "    data_line2.append(publication)\n",
        "    data_line2.append(title)\n",
        "    data_line2.append(abstract)\n",
        "    data_line2.append(others)\n",
        "\n",
        "    header = ['patent_number2', 'applicant2', 'authors2', 'ipc2', 'priority2', 'original2', 'publication2', 'title', 'abstract',\n",
        "              'other_applications']\n",
        "\n",
        "    return (data_line2)"
      ],
      "metadata": {
        "id": "EymjlcKBgyy1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "hiI7Tjyhgzcu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZo2lxo38E4n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ниже надо ввести номера патентов для парсинга"
      ],
      "metadata": {
        "id": "aPPw6K-dA1dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# original numbers for parsing\n",
        "numbers = '''CN-107856831-B\n",
        "CN-104611491-A\n",
        "CN-108559395-A\n",
        "'''"
      ],
      "metadata": {
        "id": "xtTpXM8eemTY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = numbers.replace('-', '')\n",
        "all_numbers = numbers.split()\n",
        "print('lenght of all_numbers', len(all_numbers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeYrJwLHe896",
        "outputId": "08d44c80-da25-491d-9d01-e83a12ce7ae1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenght of all_numbers 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_for_saving_results = \"/content/position of charging machine.txt\"\n",
        "\n",
        "header_1 = ['patent number', 'applicant2', 'authors2', 'ipc2', 'priority2', 'original2', 'publication2', 'title_2', 'abstract_2',\n",
        "              'other_applications_2']\n",
        "header_2 = ['patent number', 'application_number', 'title', 'INV/UM', 'filing_date', 'applicant', 'authors',\n",
        "                            'publiction_date', 'ipc', 'claims', 'status', 'abstract', 'other_applications']\n",
        "try:\n",
        "    saved_data = pd.read_csv(file_for_saving_results, sep='\\t')\n",
        "    parsed_numbers = saved_data['original_number'].values\n",
        "except:\n",
        "    parsed_numbers = []\n",
        "    with open(file_for_saving_results, 'a', encoding=\"utf-8\") as file:\n",
        "        file.writelines('\\t'.join(['original_number'] + header_2 + header_1) + '\\n')\n",
        "    print(\"creating new file\")\n",
        "\n",
        "remaining_numbers = list(set(all_numbers) - set(parsed_numbers))\n",
        "print('remaining_numbers', remaining_numbers)\n",
        "print('total remaining', len(remaining_numbers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Og82OWytW_G",
        "outputId": "7b647f36-7c94-431e-acea-a495fd710236"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating new file\n",
            "remaining_numbers ['CN108559395A', 'CN104611491A', 'CN107856831B']\n",
            "total remaining 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# correct app_numbers\n",
        "remaining_numbers_corrected = []\n",
        "for number in remaining_numbers:\n",
        "    if number[:2] == 'WO' and len(number) == 12:\n",
        "        number = 'WO20' + number[2:] + '/en'\n",
        "    remaining_numbers_corrected.append(number)\n",
        "\n",
        "final_urls = []\n",
        "for app_num in remaining_numbers_corrected:\n",
        "  if app_num[:3] == 'US2' and len(app_num) == 14:\n",
        "      url =  app_num[:].replace('-', '')[:6] + '0' + app_num[:].replace('-', '')[6:] + '/en'\n",
        "      url = 'https://patents.google.com/patent/' + url\n",
        "      #print('corrected url', url)\n",
        "  else:\n",
        "      url = 'https://patents.google.com/patent/' + app_num[:].replace('-', '').replace('\\n', '') + '/en'\n",
        "      #print('url', url)\n",
        "  final_urls.append(url)\n",
        "\n",
        "print(final_urls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8336h8hXfbfr",
        "outputId": "81652d31-e881-4ea3-9ba7-8c1f6f9d0f97"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://patents.google.com/patent/CN108559395A/en', 'https://patents.google.com/patent/CN104611491A/en', 'https://patents.google.com/patent/CN107856831B/en']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data by url\n",
        "counter = 1\n",
        "for original_number, url in zip(remaining_numbers, final_urls[:]):\n",
        "  print(counter, '/', len(remaining_numbers))\n",
        "  counter += 1\n",
        "  print(url)\n",
        "  try:\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    driver.get(url)\n",
        "    WebDriverWait(driver, 20).until(ec.visibility_of_element_located((By.ID, 'content')))\n",
        "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
        "    data_line_google = get_data_from_google_patent(soup)\n",
        "    print('data_line_google', data_line_google)\n",
        "\n",
        "    # get espacenet url\n",
        "    all_additional_urls = [url.get('href') for url in soup.find('dl', class_='links style-scope patent-result').findAll('a')]\n",
        "    for url in all_additional_urls:\n",
        "      if 'espacenet' in url:\n",
        "        #print('espacenet_url from google', url)\n",
        "        espacenet_url = url\n",
        "        break\n",
        "\n",
        "    # get data using espacent url\n",
        "    data_line_espacenet = get_from_espacenet(espacenet_url)\n",
        "    print('data_line_espacenet', data_line_espacenet)\n",
        "    print()\n",
        "\n",
        "    with open(file_for_saving_results, 'a', encoding=\"utf-8\") as file:\n",
        "        file.writelines('\\t'.join([original_number] + data_line_google + data_line_espacenet) + '\\n')\n",
        "        #print('writing')\n",
        "  except:\n",
        "    print('smth wrong with------------------------------------->', original_number)\n",
        "  #break\n",
        "print('====================finish=========================')"
      ],
      "metadata": {
        "id": "FYec6h1Weemw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab65ea7f-b291-46f1-8ca0-a598b3c1ea80"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 / 3\n",
            "https://patents.google.com/patent/CN108559395A/en\n",
            "data_line_google ['CN108559395A', 'CN201810444863.6A', 'It is a kind of to keep a public place clean fresh-keeping anti-fouling agent and surface treatment method for ceramic tile', 'no_data', '2018-05-10', 'Foshan Sanshui Planck New Material Co Ltd;', '姚燕春;', '2021-08-24', 'C09D183/04', '1. a kind of keep a public place clean fresh-keeping anti-fouling agent for ceramic tile, it is characterised in that：Including the raw material counted in parts by weight as follows：20~98 parts of alkoxy-modified silicone oil, 0~40 part of hydroxy silicon oil, 0~40 part of silane coupling agent, 0~15 part of silica, 0.5~20Part organotin catalysts.', 'Active', 'Abstracttranslated from Keep a public place clean fresh-keeping anti-fouling agent and surface treatment method for ceramic tile the invention discloses a kind of.The anti-fouling agent includes the following raw material counted in parts by weight：20~98 parts of alkoxy-modified silicone oil, 0~40 part of hydroxy silicon oil, 0~40 part of silane coupling agent, 0~15 part of silica, 0.5~20 part of organotin catalysts.Curing type anti-fouling agent of the present invention is free of organic solvent, it is not belonging to hazardous chemical, after being surface-treated to ceramic tile by super clean bright equipment and anti-fouling agent, alkoxy-modified silicone oil in anti-fouling agent, hydrolysis occurs after contacting with the air for silane coupling agent, and under organotin catalysts effect bulk polymerization occurs for above-mentioned hydrolysate and hydroxy silicon oil, product after solidification is filled with the microcrack and pore of ceramic tile, very thin anti-soil film can also be formed in ceramic tile surface, so that the glossiness of ceramic tile improves 2~5 °, polished bricks suitable for arbitrary luminosity, glazed tile, Polished crystal tile；The super clean bright equipment that its surface treatment method is suitable for non-fire-proof and explosion-proof performance securely and reliably advantageously reduces ceramic tile processing cost.', 'CN']\n",
            "data_line_espacenet ['CN108559395A', 'FOSHAN SANSHUI PULANGKE NEW MAT CO LTD', 'YAO YANCHUN', 'C09D183/04; C09D5/16; C09D7/61; C09D7/65', 'CN201810444863 20180510', 'CN201810444863 20180510', 'no_data', 'Antifouling agent for ceramic tile cleaning and preservation and surface treatment method', 'The invention discloses an antifouling agent for ceramic tile cleaning and preservation and a surface treatment method. The antifouling agent comprises the following raw materials in parts by weight:20-98 parts of alkoxy modified silicone oil, 0-40 parts of hydroxy silicone oil, 0-40 parts of a silane coupling agent, 0-15 parts of silicone dioxide and 0.5-20 parts of an organotin catalyst. The used cured-type antifouling agent does not contain an organic solvent and is not a hazardous chemical; after surface treatment of a ceramic tile through super cleaning equipment and the antifouling agent, the alkoxy modified silicone oil and the silane coupling agent in the antifouling agent contact air, then a hydrolysis reaction is performed, and a bulk polymerization reaction is performed on a hydrolysate and the hydroxy silicone oil under the action of the organotin catalyst; a cured product fills microcracks and pores of the ceramic tile, and an ultrathin antifouling film can be also formedon the surface of the ceramic tile, so that the glossiness of the ceramic tile is improved by 2-5 degrees; the antifouling agent is applicable to polished tiles, glazed tiles and crystalized tiles with arbitrary glossiness; the surface treatment method is applicable to the super cleaning equipment with non-fireproof and explosion-proof performance and is safe and reliable, and reduction in the ceramic tile processing cost is facilitated.', 'CN108559395 (B)']\n",
            "\n",
            "2 / 3\n",
            "https://patents.google.com/patent/CN104611491A/en\n",
            "data_line_google ['CN104611491A', 'CN201510027274.4A', 'Positioning device and method for leakage detection of blast furnace cooling wall', 'no_data', '2015-01-20', 'Hebei Iron and Steel Co Ltd;Hebei Iron and Steel Group Co Ltd Chengde Branch;', '陈树军;毕忠新;张晓冬;白国成;李海军;姜汀;', '2015-05-13', 'no_data', '1. a blast furnace cooling stave leakage detection locating device, it is characterized in that: it is by water filling pressurising pipe fitting, liquid level charactron (8), water-drainage tube part three part is formed, water filling pressurising pipe fitting comprises water injection pipe (1), Fill control valves (3), nitrogen fills discharge pressure pipe (4), nitrogen fills row pressure control valve (4), liquid level charactron (8) is steel wire reinforcement transparent hose, water-drainage tube part comprises water shoot (9), water discharge valve (11), tensimeter (12), the feed-water end of water injection pipe (1) is connected with water pipe, the feed-water end of water injection pipe (1) installs Fill control valves (3), the water side of water injection pipe (1) is connected with the upper end of a checked row water tube for cooling wall of blast furnace, the tube wall of the close water side of water injection pipe (1) connects nitrogen and fills discharge pressure pipe (4), nitrogen fills the upper nitrogen of installing of discharge pressure pipe (4) and fills row pressure control valve (5), water injection pipe (1) is connected with the upper end of liquid level charactron (8), the lower end of liquid level charactron (8) is connected with water shoot (9), the water side of water shoot (9) is connected with the lower end of above-mentioned checked water tube for cooling wall of blast furnace, the discharge ends of water shoot (9) installs water discharge valve (11), at the upper setting pressure table (12) of water shoot (9).', 'Pending', 'Abstracttranslated from The invention discloses a positioning device and method for leakage detection of a blast furnace cooling wall, and belongs to the technical field of blast furnace overhauling equipment and method. The device and the method are used for leakage detection of the blast furnace cooling wall and judgment of specific locations of water leakage points on the cooling wall. According to the technical scheme, a communicating device comprises water injection pressurizing parts, a liquid level display pipe, a drain assembly and detected blast furnace cooling wall water pipes; water is injected to the detected blast furnace cooling wall water pipes from a water injection pipe, and the detected blast furnace cooling wall water pipes are pressurized through a nitrogen pressure charging and discharging pipe; through observation of the liquid level of the liquid level display pipe, whether the blast furnace cooling wall is damaged can be rapidly judged, and the leakage point locations can be accurately judged. The device is simple in structure, convenient to operate and fast in detection, and a detecting result is accurate and reliable. The method can rapidly detect leakage of the blast furnace cooling wall and can accurately position the water leakage points, the problems that are not solved for a long time are solved with the simple detection device and method, and the device and the method are firstly created in the blast furnace cooling wall maintenance technology.', 'CN']\n",
            "data_line_espacenet ['CN104611491A', 'HEBEI IRON & STEEL CO LTD', 'CHEN SHUJUN; BI ZHONGXIN; ZHANG XIAODONG; BAI GUOCHENG; LI HAIJUN; JIANG TING', 'C21B7/10; C21B7/24', 'CN20151027274 20150120', 'CN20151027274 20150120', 'no_data', 'Positioning device and method for leakage detection of blast furnace cooling wall', 'The invention discloses a positioning device and method for leakage detection of a blast furnace cooling wall, and belongs to the technical field of blast furnace overhauling equipment and method. The device and the method are used for leakage detection of the blast furnace cooling wall and judgment of specific locations of water leakage points on the cooling wall. According to the technical scheme, a communicating device comprises water injection pressurizing parts, a liquid level display pipe, a drain assembly and detected blast furnace cooling wall water pipes; water is injected to the detected blast furnace cooling wall water pipes from a water injection pipe, and the detected blast furnace cooling wall water pipes are pressurized through a nitrogen pressure charging and discharging pipe; through observation of the liquid level of the liquid level display pipe, whether the blast furnace cooling wall is damaged can be rapidly judged, and the leakage point locations can be accurately judged. The device is simple in structure, convenient to operate and fast in detection, and a detecting result is accurate and reliable. The method can rapidly detect leakage of the blast furnace cooling wall and can accurately position the water leakage points, the problems that are not solved for a long time are solved with the simple detection device and method, and the device and the method are firstly created in the blast furnace cooling wall maintenance technology.', '']\n",
            "\n",
            "3 / 3\n",
            "https://patents.google.com/patent/CN107856831B/en\n",
            "data_line_google ['CN107856831B', 'CN201710832925.6A', 'A kind of air-conditioning ventilation system and its control method for the explosion-proof place in naval vessel', 'no_data', '2017-09-15', 'Hudong Zhonghua Shipbuilding Group Co Ltd;', '施晓波;祁丽;李爱华;戴辉阳;徐成;徐菁永;', '2019-05-10', 'B63J2/08', '1. a kind of control method of the air-conditioning ventilation system for the explosion-proof place in naval vessel, which is characterized in that be used for the explosion-proof place in naval vesselAir-conditioning ventilation system include machine (1) outside the Independent air conditioning being arranged in outside explosion-proof place cabin, be arranged it is indoor explosion-proof in cabinAir-conditioning internal machine (2), air inlet electric flap (4) and air draft mechanism, air inlet electric flap (4) by be fixed on bulkhead intoAir piping (6) is connected with outboard, and air draft mechanism is connected by the exhaust duct (7) being fixed on bulkhead with outboard；It is describedThe outer machine (1) of Independent air conditioning includes cooling assembly and electric control box (12), and machine (2) includes evaporator (15), heat in explosion-proof air-conditionerPower expansion valve (16), explosion-proof fan (13), electric heater (14) and the temperature to detect the explosion-proof indoor return air temperature in place cabinIt spends sensor (17), the cooling assembly is connected by passing through the refrigerant tubing (11) of bulkhead with evaporator (15), heating powerExpansion valve (16) is fixed on evaporator (15) import, and the air inlet electric flap (4), air draft mechanism, explosion-proof fan (13), electricity addHot device (14) and temperature sensor (17) carry out technological processing for explosion protection feature；The power port of the electric control box (12) respectively with air inletElectric flap (4), air draft mechanism, cooling assembly, explosion-proof fan (13) are connected with the power end of electric heater (14), the temperatureThe temperature signal output end of sensor (17) is defeated by the control cable (18) and the signal of electric control box (12) for passing through bulkheadEnter end connection, the control signal output of electric control box (12) is respectively by passing through the control cable (18) of bulkhead and entering the wind electricityDynamic air door (4), air draft mechanism, cooling assembly, explosion-proof fan (13) are connected with the control signal input of electric heater (14)；', 'Active', 'Abstracttranslated from The invention discloses a kind of air-conditioning ventilation systems and its control method for the explosion-proof place in naval vessel, the air-conditioning ventilation system includes machine outside the Independent air conditioning being arranged in outside explosion-proof place cabin, machine is set in the indoor explosion-proof air-conditioner in cabin, enter the wind electric flap and air draft mechanism, the outer machine of Independent air conditioning includes cooling assembly and electric control box, machine includes evaporator in explosion-proof air-conditioner, heating power expansion valve, explosion-proof fan, electric heater and the temperature sensor to detect the explosion-proof indoor return air temperature in place cabin, the cooling assembly is connected by passing through the refrigerant tubing of bulkhead with evaporator, heating power expansion valve is fixed on evaporator.Control method of the invention includes manually and automatically two kinds of control models, jointly controlled by air conditioning and ventilation, guarantee explosion-proof article storage temperature requirement, flammable explosive gas is avoided to gather for a long time, guarantee the safety in explosion-proof cabin, and the control method high degree of automation, logic setting is simple to operation, control is reliable.', 'CN,CN']\n",
            "data_line_espacenet ['CN107856831B', '沪东中华造船（集团）有限公司', '施晓波, ; 祁丽, ; 李爱华, ; 戴辉阳, ; 徐成, ; 徐菁永', 'A62C3/10; B63J2/02; B63J2/08', 'CN201710832925 20170915', 'CN201710832925 20170915', 'no_data', 'Air conditioner ventilation system used for ship anti-explosion place and control method of air conditioner ventilation system', 'The invention discloses an air conditioner ventilation system used for a ship anti-explosion place and a control method of the air conditioner ventilation system. The air conditioner ventilation system comprises an independent air conditioner external unit arranged outside a cabin of the anti-explosion place, an anti-explosion air conditioner internal unit, an air inflow electric air door and an air exhausting mechanism, wherein the anti-explosion air conditioner internal unit, the air inflow electric air door and the air exhausting mechanism are arranged in the cabin. The independent air conditioner external unit comprises a refrigeration component and an electrical control box. The anti-explosion air conditioner internal unit comprises an evaporator, a thermostatic expansion valve, an anti-explosion fan, an electric heater and a temperature sensor used for detecting the temperature of return air in the cabin of the anti-explosion place. The refrigeration component communicates with the evaporator through a refrigerating agent pipeline penetrating through a cabin wall. The thermostatic expansion valve is fixed to an inlet of the evaporator. The control method includes a manual control mode and an automatic control mode. Through air conditioning and ventilation combined control, the requirement for the storage temperature of anti-explosion objects is met, inflammable and explosive gas is prevented from being accumulated for a long time, safety of the anti-explosion cabin is guaranteed, the automation degree of the control method is high, logic setting is simple and easy tooperate, and control is reliable.', 'CN107856831 (A) CN108189995 (A) CN108189995 (B)']\n",
            "\n",
            "====================finish=========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the created file\n",
        "files.download(file_for_saving_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kP2OUbIbuTny",
        "outputId": "5ded611d-fe35-49c6-b180-87872447e369"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e225277a-c2b8-4f60-bf14-fe0f658be0d1\", \"position of charging machine.txt\", 15056)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}