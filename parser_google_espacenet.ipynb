{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXdtEg/sqMsiwvZzuHTj7l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galrat/parsing/blob/main/parser_google_espacenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Взять список номеров, получить список ссылок для гугл-патентов\n",
        "2. Пройтись по всем ссылкам и спарсить данные\n",
        "3. Одновременно получить ссылки на espacenet спарсить данные оттуда\n",
        "4. объединить данные с гугл и espacenet\n",
        "5. сохранить результаты на диске"
      ],
      "metadata": {
        "id": "HkbPbzy4daIi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZIq2SFhdUqX",
        "outputId": "486a9148-24b5-473e-ebc5-6fc50e698ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.16.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.23.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "import requests\n",
        "import time\n",
        "\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as ec\n",
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "5wTHdaYLelVg"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# defs"
      ],
      "metadata": {
        "id": "abomb5QSgsiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_google_patent(soup):\n",
        "\n",
        "  # title\n",
        "  title = soup.find('div', id='wrapper').find('h1', id='title').text.replace('\\n', '').strip()\n",
        "  #print('title:', title)\n",
        "\n",
        "  # patent_number\n",
        "  patent_number = soup.find('h2', id='pubnum').text.strip().replace('\\n', '').replace('\\t', '')\n",
        "  #print('patent_number:', patent_number)\n",
        "\n",
        "  # applicant\n",
        "  author_counter = 0\n",
        "  applicant_counter = 0\n",
        "  counter = 0\n",
        "  author_check = 0\n",
        "  applicant_check = 0\n",
        "  important_people_data = soup.find('dl', class_='important-people style-scope patent-result')\n",
        "  for i in important_people_data.find_all('dt', class_='style-scope patent-result'):\n",
        "      if 'Inventor' in i.text:\n",
        "          author_counter = counter\n",
        "          author_check = 1\n",
        "      if 'Assignee' in i.text:\n",
        "          applicant_counter = counter\n",
        "          applicant_check = 1\n",
        "      counter += 1\n",
        "  #print('author_counter', author_counter, 'applicant_counter', applicant_counter)\n",
        "\n",
        "  authors = ''\n",
        "  if author_check == 1:\n",
        "      try:\n",
        "          authors_data = soup.find('dl', class_='important-people style-scope patent-result')\n",
        "          authors_data = authors_data.find_all('dt', class_='style-scope patent-result')[\n",
        "              author_counter].find_next_siblings('dd')\n",
        "          for author in authors_data:\n",
        "              if '\\n' in author.text:\n",
        "                  break\n",
        "              authors = authors + author.text + ';'\n",
        "          authors = authors.replace('\\n', '')\n",
        "      except:\n",
        "          #print('no authors data')\n",
        "          authors = ('no authors data')\n",
        "  else:\n",
        "      authors = 'no_data'\n",
        "\n",
        "  applicants = ''\n",
        "  if applicant_check == 1:\n",
        "      try:\n",
        "          applicants_data = soup.find('dl', class_='important-people style-scope patent-result')\n",
        "          applicants_data = applicants_data.find_all('dt', class_='style-scope patent-result')[\n",
        "              applicant_counter].find_next_siblings('dd')\n",
        "          for applicant in applicants_data:\n",
        "              applicants = applicants + applicant.text.strip() + ';'\n",
        "          applicants = applicants.replace('\\n', '').strip()\n",
        "      except:\n",
        "          #print('no applicants data')\n",
        "          applicants = ('no applicants data')\n",
        "  else:\n",
        "      applicants = 'no_data'\n",
        "\n",
        "  # filing_date\n",
        "  filind_date = 'no_data'\n",
        "  publication_date = 'no_data'\n",
        "  status = 'no_data'\n",
        "  dates_data = soup.find_all('div', class_='event layout horizontal style-scope application-timeline')\n",
        "  for data in dates_data:\n",
        "      if 'filed by' in data.text:\n",
        "          filind_date = data.text.split('Application')[0]\n",
        "          #print('filing date:', filind_date)\n",
        "      if 'Publication' in data.text:\n",
        "          publication_date = data.text.split('Publication')[0]\n",
        "          #print('Publication date:', publication_date)\n",
        "      if 'Status' in  data.text:\n",
        "          status = data.text.split('Status')[1].replace('\\n', '').replace('\\t', '')\n",
        "          #print('Status:', status)\n",
        "\n",
        "  # application number\n",
        "  try:\n",
        "      application_number = soup.find_all('div', class_='header style-scope application-timeline')[1].text\n",
        "      application_number = application_number.split('Application')[1].split('events')[0].replace(' ','')\n",
        "  except:\n",
        "      print('no application number data')\n",
        "      application_number = 'no data'\n",
        "  #print('application_number', application_number)\n",
        "\n",
        "\n",
        "  patent_type = 'no_data'\n",
        "  #print('ipc text', soup.find('div', class_='style-scope classification-viewer').find('div', 'style-scope classification-tree').text)\n",
        "\n",
        "  ipc_data = 'no_data'\n",
        "  try:\n",
        "      ipcs = soup.find('div', class_='style-scope classification-viewer').find_all('div', class_='style-scope classification-tree')\n",
        "      for ipc in ipcs:\n",
        "          ipc_class = ipc.find(first=True).text.strip().replace('\\n', '').replace('\\t', '')\n",
        "          #print('ipc', ipc_class)\n",
        "      #print(ipc_class)\n",
        "  except:\n",
        "      ipc_data = 'no_data'\n",
        "\n",
        "  ipc_datas = soup.find_all('div', class_='style-scope classification-tree')\n",
        "  for i in ipc_datas[:1]:\n",
        "      target = i.find_all(class_='code style-scope classification-tree')\n",
        "      #print('target ipc', target[-1].text)\n",
        "      # print(i.text.strip())\n",
        "      ipc_data = target[-1].text\n",
        "\n",
        "  # claim 1\n",
        "  try:\n",
        "      # all\n",
        "      try:\n",
        "          try:\n",
        "              all = soup.find('div', class_='claim-text style-scope patent-text').find('span',\n",
        "                                                                                        class_='notranslate style-scope patent-text').text\n",
        "          except:\n",
        "              all = soup.find('div', class_='claim-text style-scope patent-text').text\n",
        "          #print('all', all)\n",
        "      except:\n",
        "          all = soup.find('section', id='claims').find('span', class_='notranslate style-scope patent-text').text\n",
        "          #print('all', all)\n",
        "\n",
        "      # original\n",
        "      try:\n",
        "          original = soup.find('div', class_='claim-text style-scope patent-text').find('span',\n",
        "                                                                                        class_='notranslate style-scope patent-text').find(\n",
        "              'span').text\n",
        "      except:\n",
        "          try:\n",
        "              original = soup.find('section', id='claims').find('span',\n",
        "                                                                class_='notranslate style-scope patent-text').find(\n",
        "                  'span').text\n",
        "          except:\n",
        "              original = ''\n",
        "      #print('original', original)\n",
        "\n",
        "      # translation\n",
        "      claim_1 = all.replace(original, '')\n",
        "      #print('claim 1:', claim_1)\n",
        "  except:\n",
        "      claim_1 = 'no_data'\n",
        "\n",
        "  # abstract\n",
        "  abstract = ''\n",
        "  try:\n",
        "    abstract_orig = soup.find('section', id='abstract').find('span', class_='google-src-text style-scope patent-text').text#.text.replace('\\n', '').replace('\\t', '').replace('Abstracttranslated from ', '')\n",
        "    #print('abstract_orig', abstract_orig)\n",
        "    abstract_all = soup.find('section', id='abstract').text\n",
        "    #print('abstract_all', abstract_all)\n",
        "    abstract_eng = abstract_all.replace(abstract_orig, '').strip()\n",
        "    abstract_eng = abstract_eng.replace('\\n', '')\n",
        "    #print('abstract_eng', abstract_eng)\n",
        "    abstract = abstract_eng\n",
        "  except:\n",
        "    abstract = soup.find('section', id='abstract').text.replace('\\n', '')\n",
        "\n",
        "\n",
        "  # other applications county code\n",
        "  others = ''\n",
        "  other_app = soup.find('div', class_='wrap style-scope application-timeline').find('div',\n",
        "                                                                                    class_='event style-scope application-timeline').find_all(\n",
        "      'a')\n",
        "  for other in other_app:\n",
        "      country_code = other.text.strip()\n",
        "      others += country_code + ','\n",
        "  #print(others)\n",
        "\n",
        "  printing = 0\n",
        "  while printing:\n",
        "      print('patent_number:', patent_number)\n",
        "      print('application_number:', application_number)\n",
        "      print('title:', title)\n",
        "      print('type:', patent_type)\n",
        "      print('filind_date:', filind_date)\n",
        "      print('applicant:', applicants)\n",
        "      print('authors:', authors)\n",
        "      print('ipc_data:', ipc_data)\n",
        "      print('publication_date:', publication_date)\n",
        "      print('abstract:', abstract)\n",
        "      print('claim_1:', claim_1)\n",
        "      print('status:', status)\n",
        "      print('others:', others)\n",
        "      break\n",
        "\n",
        "  header = ['patent number', 'application_number', 'title', 'INV/UM', 'filing_date', 'applicant', 'autors',\n",
        "                          'publiction_date', 'ipc', 'claims', 'status', 'abstract', 'other_applications']\n",
        "  data_line = []\n",
        "  data_line.append(patent_number)\n",
        "  data_line.append(application_number)\n",
        "  data_line.append(title)\n",
        "  data_line.append(patent_type)\n",
        "  data_line.append(filind_date)\n",
        "  data_line.append(applicants)\n",
        "  data_line.append(authors)\n",
        "  data_line.append(publication_date)\n",
        "  data_line.append(ipc_data)\n",
        "  data_line.append(claim_1.replace('\\n', ''))\n",
        "  data_line.append(status)\n",
        "  data_line.append(abstract.replace('\\n', ''))\n",
        "  data_line.append(others[:-1])\n",
        "  return data_line\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1MEGPidAgu5N"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_from_espacenet(espacenet_url):\n",
        "    #print(espacenet_url)\n",
        "    data_line2 = []\n",
        "\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    driver.get(espacenet_url)\n",
        "    time.sleep(2)\n",
        "    WebDriverWait(driver, 20).until(ec.visibility_of_element_located((By.ID, 'pagebody')))\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
        "\n",
        "    #print(soup)\n",
        "    #print('---------------------\\n')\n",
        "    # title\n",
        "    title = soup.find('h3').text.strip().replace('\\n', '').replace('\\t', '')\n",
        "    #print('title:', title)\n",
        "    table = soup.find('table', class_='tableType3')\n",
        "    #print(table.text.strip())\n",
        "    app_num = soup.find('h1', class_='noBottomMargin').text.split('―')[0].split('\\n')[-1].strip().replace('\\xa0', '').replace('(', '').replace(')', '')\n",
        "\n",
        "    applicant = ''\n",
        "    authors = ''\n",
        "    ipc = ''\n",
        "    priority = ''\n",
        "    original_application = ''\n",
        "    others= ''\n",
        "\n",
        "    table_lines = table.find_all('tr')\n",
        "    for line in table_lines:\n",
        "      if 'Applicant(s):' in line.text:\n",
        "        applicant = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split())\n",
        "        applicant = applicant.split('+')[0].strip()\n",
        "        #print('applicant:', applicant)\n",
        "\n",
        "      if 'Inventor(s):' in line.text:\n",
        "        authors = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split())\n",
        "        authors = authors.split('+')[0].strip()\n",
        "        #print('authors:', authors)\n",
        "\n",
        "      if 'Classification:' in line.text:\n",
        "        ipc = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split()).split('- cooperative')[0]\n",
        "        ipc = ipc.replace('- international:', '').strip()\n",
        "        ipc = ipc.split('(IPC1-7)')[0].strip()\n",
        "        #print('ipc:', ipc)\n",
        "\n",
        "      if 'Priority number(s):' in line.text:\n",
        "        priority = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split()).split('- cooperative')[0]\n",
        "        #print('Priority:', priority)\n",
        "\n",
        "      if 'Application number:' in line.text:\n",
        "        original_application = ' '.join(line.find('td').text.replace('\\n', '').replace('\\t', '').strip().split()).split('- cooperative')[0]\n",
        "        original_application = original_application.replace('Global Dossier', '').strip()\n",
        "        #print('original_application:', original_application)\n",
        "\n",
        "      if 'Also published as:' in line.text:\n",
        "        others = ' '.join(line.find('div', id='lessPublishedAs').text.replace('\\n', '').replace('\\t', '').strip().split()).split('- cooperative')[0]\n",
        "        #others = soup.find('div', id='lessPublishedAs').text.strip()\n",
        "        #print('others:', others)\n",
        "\n",
        "\n",
        "    publication = 'no_data'\n",
        "\n",
        "    abstract = soup.find('div', class_='application article clearfix').find('p').text\n",
        "    #print(abstract)\n",
        "\n",
        "    printing = 0\n",
        "    while printing:\n",
        "        print('title:', title)\n",
        "        print('applicant:', applicant)\n",
        "        print('authors:', authors)\n",
        "        print('ipc:', ipc)\n",
        "        print('priority:', priority)\n",
        "        print('original_application:', original_application)\n",
        "        print('publication:', publication)\n",
        "        print('abstract:', abstract)\n",
        "        print('others:', others)\n",
        "        break\n",
        "\n",
        "    data_line2.append(app_num)\n",
        "    data_line2.append(applicant)\n",
        "    data_line2.append(authors)\n",
        "    data_line2.append(ipc)\n",
        "    data_line2.append(priority)\n",
        "    data_line2.append(original_application)\n",
        "    data_line2.append(publication)\n",
        "    data_line2.append(title)\n",
        "    data_line2.append(abstract)\n",
        "    data_line2.append(others)\n",
        "\n",
        "    header = ['patent_number2', 'applicant2', 'authors2', 'ipc2', 'priority2', 'original2', 'publication2', 'title', 'abstract',\n",
        "              'other_applications']\n",
        "\n",
        "    return (data_line2)"
      ],
      "metadata": {
        "id": "EymjlcKBgyy1"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "hiI7Tjyhgzcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# original numbers for parsing\n",
        "numbers = '''US6515088B2\n",
        "TW572959B\n",
        "TW593350B\n",
        "TW593514B\n",
        "US6825290B2\n",
        "KR100474528B1\n",
        "CN1200987C\n",
        "US6900280B2\n",
        "US6900267B2\n",
        "KR100506343B1\n",
        "KR100511194B1\n",
        "KR100511187B1\n",
        "TWI239339B'''\n",
        "#numbers = '''US6515088B2'''"
      ],
      "metadata": {
        "id": "xtTpXM8eemTY"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_numbers = numbers.split()\n",
        "print('lenght of all_numbers', len(all_numbers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeYrJwLHe896",
        "outputId": "b7577489-1547-4962-d72e-60c843fdad81"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenght of all_numbers 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "teRpcnpK5RNW"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_for_saving_results = \"/content/saved_results.txt\"\n",
        "\n",
        "header_1 = ['patent number', 'applicant2', 'authors2', 'ipc2', 'priority2', 'original2', 'publication2', 'title_2', 'abstract_2',\n",
        "              'other_applications_2']\n",
        "header_2 = ['patent number', 'application_number', 'title', 'INV/UM', 'filing_date', 'applicant', 'authors',\n",
        "                            'publiction_date', 'ipc', 'claims', 'status', 'abstract', 'other_applications']\n",
        "try:\n",
        "    saved_data = pd.read_csv(file_for_saving_results, sep='\\t')\n",
        "    parsed_numbers = saved_data['original_number'].values\n",
        "except:\n",
        "    parsed_numbers = []\n",
        "    with open(file_for_saving_results, 'a', encoding=\"utf-8\") as file:\n",
        "        file.writelines('\\t'.join(['original_number'] + header_2 + header_1) + '\\n')\n",
        "    print(\"creating new file\")\n",
        "\n",
        "remaining_numbers = list(set(all_numbers) - set(parsed_numbers))\n",
        "print('remaining_numbers', remaining_numbers)\n",
        "print('total remaining', len(remaining_numbers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Og82OWytW_G",
        "outputId": "398d0e05-b822-4939-f3fd-e33feea5641f"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remaining_numbers ['TW593350B', 'KR100511194B1', 'TWI239339B', 'US6900280B2', 'KR100506343B1', 'US6825290B2', 'CN1200987C', 'TW572959B', 'KR100474528B1', 'KR100511187B1', 'US6900267B2', 'TW593514B']\n",
            "total remaining 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# correct app_numbers\n",
        "remaining_numbers_corrected = []\n",
        "for number in remaining_numbers:\n",
        "    if number[:2] == 'WO' and len(number) == 12:\n",
        "        number = 'WO20' + number[2:] + '/en'\n",
        "    remaining_numbers_corrected.append(number)\n",
        "\n",
        "final_urls = []\n",
        "for app_num in remaining_numbers_corrected:\n",
        "  if app_num[:3] == 'US2' and len(app_num) == 14:\n",
        "      url =  app_num[:].replace('-', '')[:6] + '0' + app_num[:].replace('-', '')[6:] + '/en'\n",
        "      url = 'https://patents.google.com/patent/' + url\n",
        "      #print('corrected url', url)\n",
        "  else:\n",
        "      url = 'https://patents.google.com/patent/' + app_num[:].replace('-', '').replace('\\n', '') + '/en'\n",
        "      #print('url', url)\n",
        "  final_urls.append(url)\n",
        "\n",
        "print(final_urls)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8336h8hXfbfr",
        "outputId": "1bfb66f6-42b4-4667-e78a-fc9c95707440"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://patents.google.com/patent/TW593350B/en', 'https://patents.google.com/patent/KR100511194B1/en', 'https://patents.google.com/patent/TWI239339B/en', 'https://patents.google.com/patent/US6900280B2/en', 'https://patents.google.com/patent/KR100506343B1/en', 'https://patents.google.com/patent/US6825290B2/en', 'https://patents.google.com/patent/CN1200987C/en', 'https://patents.google.com/patent/TW572959B/en', 'https://patents.google.com/patent/KR100474528B1/en', 'https://patents.google.com/patent/KR100511187B1/en', 'https://patents.google.com/patent/US6900267B2/en', 'https://patents.google.com/patent/TW593514B/en']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data by url\n",
        "for original_number, url in zip(remaining_numbers, final_urls[:]):\n",
        "  print(url)\n",
        "\n",
        "  options = Options()\n",
        "  options.add_argument(\"--headless\")\n",
        "  options.add_argument('--no-sandbox')\n",
        "  options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36')\n",
        "  driver = webdriver.Chrome(options=options)\n",
        "  driver.get(url)\n",
        "  WebDriverWait(driver, 20).until(ec.visibility_of_element_located((By.ID, 'content')))\n",
        "  soup = BeautifulSoup(driver.page_source, 'lxml')\n",
        "  data_line_google = get_data_from_google_patent(soup)\n",
        "  print('data_line_google', data_line_google)\n",
        "\n",
        "  # get espacenet url\n",
        "  all_additional_urls = [url.get('href') for url in soup.find('dl', class_='links style-scope patent-result').findAll('a')]\n",
        "  for url in all_additional_urls:\n",
        "    if 'espacenet' in url:\n",
        "      print('espacenet_url', url)\n",
        "      espacenet_url = url\n",
        "  print()\n",
        "\n",
        "  # get data using espacent url\n",
        "  data_line_espacenet = get_from_espacenet(espacenet_url)\n",
        "  print(data_line_espacenet)\n",
        "\n",
        "\n",
        "  with open(file_for_saving_results, 'a', encoding=\"utf-8\") as file:\n",
        "      file.writelines('\\t'.join([original_number] + data_line_google + data_line_espacenet) + '\\n')\n",
        "      #print('writing')\n",
        "\n",
        "  #break\n",
        "print('====================finish=========================')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYec6h1Weemw",
        "outputId": "b951c7f1-d039-4687-bb34-e49508917ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://patents.google.com/patent/TW593350B/en\n",
            "data_line_google ['TW593350B', 'TW090125654A', 'The method for preparing ethylene-vinylacetate copolymer as well as the saponification substance obtained by this way and the moldings containing it', 'no_data', '2001-10-17', 'no_data', 'Kazuyori Yoshimi;', '2004-06-21', 'C08F210/08', ' Patent No. 593350, Patent Application No. 90 1 25654 \"Method for the production of ethylene-vinyl acetate copolymers, saponification of copolymers obtained by this method and shaped articles containing it\" (Amended on September 26, 1992) 6 Scope of patent application: 1. A method for producing an ethylene-vinyl acetate copolymer. When a polymerization initiator is used, ethylene and vinyl acetate are copolymerized to produce an ethylene-vinyl acetate copolymer having an ethylene content of 5 to 60 mol%. It is characterized in that an aliphatic alcohol having 1 to 4 carbons is used as a polymerization solvent, and the content of acetaldehyde relative to vinyl acetate in the raw material vinyl acetate or an aliphatic alcohol solution having 1 to 4 carbon atoms in vinyl acetate is within 0 ~ 2 0 0 ppm, the saturated acetate content in vinyl acetate is 10 ~ 1,500 ppm, and the polymerization is performed at a temperature of 30 ~ 150 ° C. 2. For example, the method for producing an ethylene-vinyl acetate copolymer according to item 1 of the patent application, wherein ethylene, vinyl acetate, a polymerization initiator, and a polymerization solvent are continuously introduced into a polymerization tank, and ethylene is continuously derived from the polymerization tank. Vinyl acetate copolymer. 3. For example, the method for preparing an ethylene-vinyl acetate copolymer according to item 2 of the scope of the patent application includes the following steps: (A) Introducing an aliphatic alcohol solution having a carbon number of 1 to 4 of vinyl acetate or vinyl acetate and providing cooling The heat exchanger of the mechanism, the ethylene derived from the polymerization tank is introduced into the heat exchanger, and a small part of the ethylene g is absorbed in the vinyl acetate or vinyl acetate solution in the heat exchanger; (B) the absorption Ethylene vinyl acetate or vinyl acetate solution \\'593350 6. The scope of the patent application is introduced into the polymerization tank and mixed with the polymerization solution; and (c) In the polymerization tank, the ethylene in the polymerization solution that exceeds the solubility of ethylene is vaporized, and heat is introduced. Inside the exchanger. 4. If the third method of producing an ethylene-vinyl acetate copolymer according to the scope of the patent application is\\' where the temperature of the vinyl acetate or vinyl acetate solution introduced into the polymerization tank to absorb ethylene is 1 (° C), the polymerization in the polymerization tank is performed. When the temperature of the solution is T2 (° C), it must meet the relationship of 1 &lt; 5. The method for producing an ethylene-vinyl acetate copolymer according to item 3 of the application, wherein the vinyl acetate or vinyl acetate solution is passed through a wet-wall multi-tube heat exchanger provided with a cooling mechanism in a thin film form. 6. The method for preparing an ethylene-vinyl acetate copolymer according to item 1 of the application, wherein the aliphatic alcohol having 1 to 4 carbon atoms is selected from at least one of methanol and ethanol, and the saturated acetate is selected from saturated methyl acetate. And at least one of ethyl acetate. 7. The method for preparing an ethylene-vinyl acetate copolymer according to item 1 of the application, wherein the polymerization initiator is selected from the group consisting of a difluorenyl peroxide-based initiator, a valeronitrile-based initiator, and a peroxydicarbonate-based initiator. At least ~ species. 8. The method for preparing an ethylene-vinyl acetate copolymer according to item 1 of the patent application, wherein a compound having a conjugated double chain having a molecular weight of 68 to 1,000 is added to the solution after polymerization. 9. An ethylene-acetic acid-vinyl ester copolymer saponified product obtained by applying an ethylene-acetic acid-vinyl ester copolymer obtained by applying for the scope of the first method of the patented scope of application for every 5,933,350 patent applications. 10. The ethylene-vinyl acetate copolymer saponified product according to item 9 of the patent application scope, which contains a boron compound. 11. A molded article containing a saponified product of an ethylene-vinyl acetate copolymer according to item 9 of the application.', 'no_data', 'Abstracttranslated from The objects of the present invention are (1) improving the stability of melt extrusion, (2) improving the ability of melt molding, (3) reducing the incidence of coloring, (4) reducing the incidence of gel, when preparing the saponification substance of ethylene-vinylacetate copolymer (EVOH). The ethylene and vinylacetate are copolymerized with the polymerization initiator for preparing the ethylene-vinylacetate copolymer (EVA) containing the 5 to 60% by mole of ethylene. And the fatty alcohol containing below 4 of carbon atoms are used as polymerizing solvent. The contents of acetaldehyde and saturated acetate are respectively below 200 ppm and 10 to 1500 ppm, and polymerizing temperature is 30 to 150 DEG C.', 'TW,US,CN,GB,KR,DE,AT,EP']\n",
            "espacenet_url https://worldwide.espacenet.com/publicationDetails/biblio?CC=TW&NR=593350B&KC=B&FT=D\n",
            "\n",
            "['TW593350B', 'KURARAY CO [JP]', 'YOSHIMI KAZUYORI [JP]', 'B32B27/32; C08F2/06; C08F210/02; C08F210/08; C08F218/08; C08F8/12;', 'JP20000317361 20001018', 'TW20010125654 20011017', 'no_data', 'The method for preparing ethylene-vinylacetate copolymer as well as the saponification substance obtained by this way and the moldings containing it', 'The objects of the present invention are (1) improving the stability of melt extrusion, (2) improving the ability of melt molding, (3) reducing the incidence of coloring, (4) reducing the incidence of gel, when preparing the saponification substance of ethylene-vinylacetate copolymer (EVOH). The ethylene and vinylacetate are copolymerized with the polymerization initiator for preparing the ethylene-vinylacetate copolymer (EVA) containing the 5 to 60% by mole of ethylene. And the fatty alcohol containing below 4 of carbon atoms are used as polymerizing solvent. The contents of acetaldehyde and saturated acetate are respectively below 200 ppm and 10 to 1500 ppm, and polymerizing temperature is 30 to 150 DEG C.', 'ATE335018 (T1) CN1179989 (C) CN1350010 (A) DE60121890 (T2) EP1199317 (A2) more']\n",
            "https://patents.google.com/patent/KR100511194B1/en\n",
            "data_line_google ['KR100511194B1', 'KR10-2003-0079301A', 'Capsulized or Surface Functionalized Monodisperse Polymer Particle and Method of Preparing the Same', 'no_data', '2003-11-11', 'no_data', '박진규;홍재근;', '2005-08-30', 'C08F2/24', ' Preparing a polymer dispersion (1) by dispersing a polymer fine particle having a full-interpenetrating polymer network structure in an aqueous solution in which an oxidation-reduction initiator, an acid, and an emulsifier are dissolved together;', 'no_data', 'Abstracttranslated from Korean The encapsulated or surface functionalized monodisperse polymer microparticles (5) according to the present invention may be prepared by dispersing polymer microparticles having a full-interpenetrating polymer network structure in an aqueous solution in which an oxidation-reduction initiator, an acid, and an emulsifier are dissolved together. Dispersing to prepare a polymer dispersion (1); Dispersion 2 is separately prepared by mixing and stirring an organic solvent in which a monomer, an initiator and a crosslinking agent are dissolved, and an aqueous solution in which a dispersion stabilizer is dissolved; The mixed and stirred dispersion (2) is again mixed and stirred with the polymer dispersion (1) to prepare a polymer dispersion (3) collected by the mixed and stirred dispersion; Depositing and polymerizing the collected polymer dispersion (3) to form a deposition layer on the surface of the polymer dispersion to produce a surface functionalized polymer dispersion (4); And it is characterized in that the step of removing the organic solvent on the surface functionalized polymer dispersion (4), it can be used as a spacer for a liquid crystal display (LCD).', 'KR']\n",
            "espacenet_url https://worldwide.espacenet.com/publicationDetails/biblio?CC=KR&NR=100511194B1&KC=B1&FT=D\n",
            "\n",
            "['KR100511194B1', 'CHEIL INDUSTRIES INC', 'HONG, JAE KEUN, ; PARK, JIN GYU', 'C08F2/30;', 'KR20030079301 20031111', 'KR20030079301 20031111', 'no_data', 'Capsulized or Surface Functionalized Monodisperse Polymer Particle and Method of Preparing the Same', '', 'KR20050045290 (A)']\n",
            "https://patents.google.com/patent/TWI239339B/en\n",
            "data_line_google ['TWI239339B', 'TW090122735A', 'A method of toughening thermoplastic polymers and thermoplastic compositions produced thereby', 'no_data', '2001-09-13', 'no_data', 'Willie Lau;Rheenen Paul Ralph Van;', '2005-09-11', 'C08J3/00', ' ', 'no_data', 'Abstracttranslated from A method of forming a toughened article from a blend of a thermoplastic polymer and a comb copolymer is disclosed, along with the toughened article produced thereby. Compositions such as solids blends and melt blends, including a thermoplastic polymer and a comb copolymer, are also disclosed.', 'CN,DE,EP,JP,CN,JP,CN,AR,DE,TW,EP,CN,JP,KR,AR,AU,DE,AU,WO,EP,WO,EP,US,DE,AR,AU,US,US,AU,WO,JP,TW,KR,WO,WO,KR,AR,KR,AU,TW,AU,WO,US,CN,WO,AU,DE,US,TW,TW,CN,EP,EP,EP,AR,KR,CN,AU,JP,JP,JP,US,AR,AR,TW,AR,US,US,JP']\n",
            "espacenet_url https://worldwide.espacenet.com/publicationDetails/biblio?CC=TW&NR=I239339B&KC=B&FT=D\n",
            "\n",
            "['TWI239339B', 'ROHM & HAAS [US]', 'LAU WILLIE [US]; VAN RHEENEN PAUL RALPH [US]', 'B29C48/90; B32B27/08; C08F257/02; C08F265/04; C08F265/06; C08F290/00; C08F290/04; C08F290/06; C08F291/00; C08F293/00; C08F4/00; C08F4/16; C08J3/02; C08J5/18; C08K3/20; C08L101/00; C08L23/08; C08L23/20; C08L25/12; C08L27/04; C08L27/06; C08L27/24; C08L51/00; C08L53/00; C08L53/02; C08L55/00; C08L55/02; C08L67/02; C08L67/06; C08L69/00; C08L77/00; C08L77/02; C08L77/06; C09D133/02; C09D151/00; C09D153/00; C09D155/00; C09D157/00; C09D5/02; C09J133/00; C09J133/10; C09J151/00; C08L23/10; C08L23/16; C08L23/22; C08L33/00; C08L33/06; C08L33/10;', 'US20000232414P 20000914', 'TW20010122735 20010913', 'no_data', 'A method of toughening thermoplastic polymers and thermoplastic compositions produced thereby', 'A method of forming a toughened article from a blend of a thermoplastic polymer and a comb copolymer is disclosed, along with the toughened article produced thereby. Compositions such as solids blends and melt blends, including a thermoplastic polymer and a comb copolymer, are also disclosed.', 'AR030724 (A1) AR030729 (A1) AR030730 (A1) AR031989 (A1) AR033394 (A1) more']\n",
            "https://patents.google.com/patent/US6900280B2/en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the created file\n",
        "files.download(file_for_saving_results)"
      ],
      "metadata": {
        "id": "kP2OUbIbuTny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}